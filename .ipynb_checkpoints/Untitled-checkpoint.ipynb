{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset import MRIDataset\n",
    "from env import Env\n",
    "from model import MyFcn\n",
    "from pixel_wise_a2c import PixelWiseA2C\n",
    "\n",
    "\n",
    "from utils import adjust_learning_rate as adjust_learning_rate\n",
    "from utils import Config as Config\n",
    "\n",
    "def parse():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', default='config.yml', type=str,\n",
    "                        dest='config', help='to set the parameters')\n",
    "    parser.add_argument('--log_dir', default='log', type=str,\n",
    "                        dest='log_dir', help='the root of log')\n",
    "    parser.add_argument('--gpu', default=[0, 1], nargs='+', type=int,\n",
    "                        dest='gpu', help='the gpu used')\n",
    "    parser.add_argument('--root', default='/home/lwt/MRI_RL/DAGAN/data/MICCAI13_RL/', type=str,\n",
    "                        dest='root', help='the root of images')\n",
    "    #parser.add_argument('--train_dir', nargs='+', type=str,\n",
    "    #                    dest='train_dir', help='the path of train file')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def test(model, a2c, config, args):\n",
    "    env = Env(config.move_range)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset = MRIDataset(root=args.root, image_set='test', transform=False),\n",
    "        batch_size=config.batch_size, shuffle=False,\n",
    "        num_workers=config.workers, pin_memory=False)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    reward_sum = 0\n",
    "    for i, (ori_image, image) in enumerate(test_loader):\n",
    "        if i == 30:\n",
    "            actions = actions.astype(np.uint8)\n",
    "            total = actions.size\n",
    "            for a in range(9):\n",
    "                print(a, np.sum(actions==a) / total, end=',')\n",
    "            break\n",
    "        ori_image = ori_image.numpy()\n",
    "        image = image.numpy()\n",
    "        env.reset(ori_image=ori_image, image=image) \n",
    "\n",
    "        for j in range(config.episode_len):\n",
    "            image_input = Variable(torch.from_numpy(image).cuda(), volatile=True)\n",
    "            pout, vout = model(image_input)\n",
    "            actions = a2c.act(pout, deterministic=False)\n",
    "            image, reward = env.step(actions)\n",
    "            image = np.clip(image, 0, 1)\n",
    "\n",
    "            reward_sum += np.sum(reward)\n",
    "\n",
    "    print('test finished: reward ', reward_sum / i)\n",
    "\n",
    "def train():\n",
    "    config = Config('config.yml')\n",
    "\n",
    "#    torch.manual_seed(args.seed)\n",
    "#    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "#    if args.cuda and torch.cuda.is_available() and args.cuda_deterministic:\n",
    "#        torch.backends.cudnn.benchmark = False\n",
    "#        torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    log_dir = os.path.expanduser('log')\n",
    "#    eval_log_dir = log_dir + \"_eval\"\n",
    "#    utils.cleanup_log_dir(log_dir)\n",
    "#    utils.cleanup_log_dir(eval_log_dir)\n",
    "\n",
    "    #torch.set_num_threads(4)\n",
    "#    torch.set_num_threads(1)\n",
    "    #device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "\n",
    "    env = Env(config.move_range)\n",
    "    model = MyFcn(num_actions=config.num_actions)\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1]).cuda()\n",
    "    a2c = PixelWiseA2C(model=None, optimizer=None, t_max=100000, gamma=config.gamma, beta=1e-2)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), config.base_lr)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset = MRIDataset(root='/home/lwt/MRI_RL/DAGAN/data/MICCAI13_RL/', image_set='train', transform=False),\n",
    "        batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=config.workers, pin_memory=False)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    episodes = 0\n",
    "    while episodes < config.num_episodes:\n",
    "\n",
    "        for i, (ori_image, image) in enumerate(train_loader):\n",
    "            learning_rate = adjust_learning_rate(optimizer, episodes, config.base_lr, policy=config.lr_policy, policy_parameter=config.policy_parameter)\n",
    "            ori_image = ori_image.numpy()\n",
    "            image = image.numpy()\n",
    "            env.reset(ori_image=ori_image, image=image) \n",
    "\n",
    "            reward = np.zeros((1))\n",
    "\n",
    "            for j in range(config.episode_len):\n",
    "                image_input = Variable(torch.from_numpy(image).cuda())\n",
    "                reward_input = Variable(torch.from_numpy(reward).cuda())\n",
    "                pout, vout = model(image_input)\n",
    "                actions = a2c.act_and_train(pout, vout, reward_input)\n",
    "                previous_image = image\n",
    "                image, reward = env.step(actions)\n",
    "                if i % 20 == 0:\n",
    "                    print('reward', j, np.mean(reward))\n",
    "                image = np.clip(image, 0, 1)\n",
    "                print(image.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #for step in range(args.num_steps):\n",
    "        #    # Sample actions\n",
    "        #    with torch.no_grad():\n",
    "        #        value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(\n",
    "        #            rollouts.obs[step], rollouts.recurrent_hidden_states[step],\n",
    "        #            rollouts.masks[step])\n",
    "\n",
    "        #    # Obser reward and next obs\n",
    "        #    obs, reward, done, infos = envs.step(action)\n",
    "\n",
    "        #    for info in infos:\n",
    "        #        if 'episode' in info.keys():\n",
    "        #            episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "        #    # If done then clean the history of observations.\n",
    "        #    masks = torch.FloatTensor(\n",
    "        #        [[0.0] if done_ else [1.0] for done_ in done])\n",
    "        #    bad_masks = torch.FloatTensor(\n",
    "        #        [[0.0] if 'bad_transition' in info.keys() else [1.0]\n",
    "        #         for info in infos])\n",
    "        #    rollouts.insert(obs, recurrent_hidden_states, action,\n",
    "        #                    action_log_prob, value, reward, masks, bad_masks)\n",
    "\n",
    "        #with torch.no_grad():\n",
    "        #    next_value = actor_critic.get_value(\n",
    "        #        rollouts.obs[-1], rollouts.recurrent_hidden_states[-1],\n",
    "        #        rollouts.masks[-1]).detach()\n",
    "\n",
    "#       # if args.gail:\n",
    "#       #     if j >= 10:\n",
    "#       #         envs.venv.eval()\n",
    "#\n",
    "#       #     gail_epoch = args.gail_epoch\n",
    "#       #     if j < 10:\n",
    "#       #         gail_epoch = 100  # Warm up\n",
    "#       #     for _ in range(gail_epoch):\n",
    "#       #         discr.update(gail_train_loader, rollouts,\n",
    "#       #                      utils.get_vec_normalize(envs)._obfilt)\n",
    "#\n",
    "#       #     for step in range(args.num_steps):\n",
    "#       #         rollouts.rewards[step] = discr.predict_reward(\n",
    "#       #             rollouts.obs[step], rollouts.actions[step], args.gamma,\n",
    "#       #             rollouts.masks[step])\n",
    "\n",
    "        #rollouts.compute_returns(next_value, args.use_gae, args.gamma,\n",
    "        #                         args.gae_lambda, args.use_proper_time_limits)\n",
    "\n",
    "        #value_loss, action_loss, dist_entropy = agent.update(roll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-82c488320078>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-82c488320078>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    train() --gpu 0\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train() --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = torch.rand([32,1,64,64])\n",
    "q = Variable(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 64, 64])\n",
      "torch.Size([32, 64, 64, 64])\n",
      "torch.Size([32, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "out1,out2=a(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 0, 0: 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand([5,30])\n",
    "b = Variable(a)\n",
    "c = Categorical(a)\n",
    "m = c.sample()\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
