workers: 4
display: 20
batch_size: 16
#start_iters: 0
num_episodes: 4002 #30000
test_episodes: 1000 #3000
save_episodes: 4000
iter_size: 30
#-------------rl_related--------------------#
episode_len: 3 #2
gamma: 0.5 #0.95
num_actions: 13
move_range: 3
reward_method: 'abs'
#-------------lr_policy--------------------#
base_lr: 0.2
# step
lr_policy: 'step'
policy_parameter:
  gamma: 0.5
  step_size: 1000
# exp
# lr_policy: 'exp'
# policy_parameter:
#   gamma: 0.99
# 
# inv
# lr_policy: 'inv'
# policy_parameter:
#   gamma: 0.1
#   power: 0.1
# 
# multistep
#lr_policy: 'multistep'
#policy_parameter:
  #stepvalue: [20000, 35000, 45000]
  #gamma: 0.1
# 
# poly
#lr_policy: 'poly'
#policy_parameter:
#  power: 0.9
#  max_iter: 30000
# 
# sigmoid
# lr_policy: 'sigmoid'
# policy_parameter:
#   gamma: 0.9
#   stepsize: 5000
#lr_policy: 'multistep-poly'
#policy_parameter:
  #stepvalue: [12435, 24870, 37350, 49740]
  #max_iter: 62175
  #gamma: 0.333
  #power: 1.2
